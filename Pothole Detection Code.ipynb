{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**1.   Intall Dependencies**\n",
        "\n"
      ],
      "metadata": {
        "id": "KLtJV5qxFz90"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sngdoc4bFbsa"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow\n",
        "!pip install tensorflow-addons\n",
        "!pip list\n",
        "!unzip -q path_to_your_zip.zip\n",
        "!pip install Pillow\n",
        "!pip install opencv-contrib-python"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**2.   Import Libraries**\n",
        "\n"
      ],
      "metadata": {
        "id": "WytIzenxF6jt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import imghdr\n",
        "import cv2\n",
        "import zipfile\n",
        "import shutil\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import traceback\n",
        "from google.colab import files\n",
        "import zipfile\n",
        "from PIL import Image\n",
        "import io\n"
      ],
      "metadata": {
        "id": "U19LmHVXF5ms"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**3. Image Preprocessing**\n",
        "\n"
      ],
      "metadata": {
        "id": "oUsi6-5ONH-6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def auto_canny(image, sigma=0.1):\n",
        "\n",
        "    # Convert the PIL image to a NumPy array\n",
        "    image = np.array(image)\n",
        "\n",
        "    # Resize image\n",
        "    image = cv2.resize(image, (224, 224))\n",
        "\n",
        "    # Convert the image to grayscale if it's not already\n",
        "    if len(image.shape) > 2:\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    else:\n",
        "        gray = image\n",
        "\n",
        "    # Apply Gaussian blur to reduce noise\n",
        "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "\n",
        "    # Perform adaptive thresholding to segment the image\n",
        "    _, thresh = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "\n",
        "    # Apply automatic Canny edge detection using the computed median\n",
        "    v = np.median(blurred)\n",
        "    lower = int(max(0, (1.0 - sigma) * v))\n",
        "    upper = int(min(255, (1.0 + sigma) * v))\n",
        "    canny = cv2.Canny(blurred, lower, upper)\n",
        "\n",
        "    # Dilation to connect adjacent edges\n",
        "    kernel = np.ones((3,3), np.uint8)\n",
        "    canny = cv2.dilate(canny, kernel, iterations=1)\n",
        "\n",
        "    # Morphological closing to connect edges\n",
        "    kernel = np.ones((5, 5), np.uint8)\n",
        "    closed = cv2.morphologyEx(canny, cv2.MORPH_CLOSE, kernel)\n",
        "\n",
        "    # Applying threshold as mask\n",
        "    canny = cv2.bitwise_and(closed, thresh)\n",
        "\n",
        "    # Contour detection\n",
        "    contours, _ = cv2.findContours(canny, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # Area filtering\n",
        "    min_area = 100\n",
        "    max_area = 10000\n",
        "    final_contours = []\n",
        "    for cnt in contours:\n",
        "        area = cv2.contourArea(cnt)\n",
        "        if min_area < area < max_area:\n",
        "            final_contours.append(cnt)\n",
        "\n",
        "    # Draw remaining contours on a new image\n",
        "    contour_img = cv2.drawContours(np.zeros_like(canny), final_contours, -1, (255, 255, 255), 1)\n",
        "\n",
        "    return contour_img\n",
        "\n",
        "# Define folders and processed folders\n",
        "base_folders = ['Training', 'Testing']\n",
        "processed_folders = ['Training_Processed', 'Testing_Processed']\n",
        "\n",
        "# Process images and save the outputs\n",
        "for base_folder, processed_folder in zip(base_folders, processed_folders):\n",
        "    os.makedirs(processed_folder, exist_ok=True)\n",
        "    images = [image for image in os.listdir(base_folder) if image.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "    for img in images:\n",
        "        im = Image.open(os.path.join(base_folder, img))\n",
        "        canny = auto_canny(im)\n",
        "        cv2.imwrite(os.path.join(processed_folder, img), canny)  # Save processed image"
      ],
      "metadata": {
        "id": "wkJj7a55HCgc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "**4.   Deep Learning**\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "F3Dgw0E-8Yhk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "  **4.1   CNN Model**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0pglOXoN8oNV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from PIL import Image\n",
        "import cv2\n",
        "\n",
        "\n",
        "# Mapping class data from Excel\n",
        "class_data = pd.read_excel('/content/ImageProcessingdataset.xlsx')  # Your Excel file\n",
        "class_mapping = {'S': 0, 'A': 1, 'B': 2, 'C': 3}\n",
        "class_data['Level'] = class_data['Level'].map(class_mapping)\n",
        "class_dict = dict(zip(class_data['Image ID'], class_data['Level']))\n",
        "\n",
        "def get_label(file_path):\n",
        "    # If the input is a tensor, decode it\n",
        "    if isinstance(file_path, tf.Tensor):\n",
        "        # https://stackoverflow.com/questions/40388792/how-to-decode-a-numpy-array-of-encoded-literals-strings-in-python3-attributeerr\n",
        "        file_path = file_path.numpy().decode('utf-8')\n",
        "\n",
        "    image_id = os.path.basename(file_path).split('.')[0]  # to only consider the image_ID without the extension\n",
        "\n",
        "    # Retrieve the label\n",
        "    try:\n",
        "        label = class_dict[image_id]\n",
        "    except KeyError:\n",
        "        print(f\"Filename not found in class_dict: {image_id}\")\n",
        "        label = -1  # Use -1 for not existing label (there is a problem here)\n",
        "    return tf.cast(label, tf.int32)\n",
        "\n",
        "\n",
        "def process_path(file_path):\n",
        "    # We should decode the file path, necessary when using tf.py_function\n",
        "    # https://stackoverflow.com/questions/69859878/tensorflow-2-6-0-error-during-model-fit-after-using-tf-py-function-valueerror\n",
        "    # https://stackoverflow.com/questions/40388792/how-to-decode-a-numpy-array-of-encoded-literals-strings-in-python3-attributeerr\n",
        "    file_path = file_path.numpy().decode('utf-8')\n",
        "\n",
        "    # Read and process the image\n",
        "    img = tf.io.read_file(file_path)\n",
        "    img = tf.image.decode_jpeg(img, channels=1)  # Assuming images are grayscale\n",
        "    img = tf.image.resize(img, [224, 224])\n",
        "    img = img / 255.0  # Normalize images\n",
        "\n",
        "    label = tf.py_function(func=get_label, inp=[file_path], Tout=tf.int32)\n",
        "    return img, label\n",
        "\n",
        "\n",
        "# Set output shapes explicitly for efficiency\n",
        "def set_shapes(img, label):\n",
        "    img.set_shape([224, 224, 1])\n",
        "    label.set_shape([])\n",
        "    return img, label\n",
        "\n",
        "\n",
        "\n",
        "def create_dataset(file_paths):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(file_paths)\n",
        "    # Wrap process_path to handle tensor inputs correctly\n",
        "    dataset = dataset.map(lambda x: tf.py_function(func=process_path, inp=[x], Tout=[tf.float32, tf.int32]))\n",
        "    dataset = dataset.map(set_shapes)  # I needed to apply set_shapes to ensure correct tensor shapes\n",
        "\n",
        "    # Filter out invalid labels\n",
        "    dataset = dataset.filter(lambda img, label: label >= 0)\n",
        "\n",
        "    return dataset.batch(20).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "\n",
        "# Load images and their paths\n",
        "train_dir = '/content/Training_Processed'\n",
        "test_dir = '/content/Testing_Processed'\n",
        "train_files = [os.path.join(train_dir, fname) for fname in os.listdir(train_dir) if fname.endswith(('.jpg', '.jpeg'))]\n",
        "test_files = [os.path.join(test_dir, fname) for fname in os.listdir(test_dir) if fname.endswith(('.jpg', '.jpeg'))]\n",
        "\n",
        "\n",
        "# Create datasets for training and testing\n",
        "train_dataset = create_dataset(train_files)\n",
        "test_dataset = create_dataset(test_files)\n",
        "\n",
        "# CNN Model Definition\n",
        "def create_cnn_model():\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 1)),\n",
        "        MaxPooling2D(2, 2),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        MaxPooling2D(2, 2),\n",
        "        Conv2D(128, (3, 3), activation='relu'),\n",
        "        MaxPooling2D(2, 2),\n",
        "        Flatten(),\n",
        "        Dense(512, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(4, activation='softmax')  # Use 'softmax' for multi-class classification\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Create and train the model\n",
        "model = create_cnn_model()\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=10,\n",
        "    validation_data=test_dataset\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwpGE0AOfYq7",
        "outputId": "9c01545b-1b0c-463b-9c92-beba577eafef"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "18/18 [==============================] - 66s 4s/step - loss: 1.3364 - accuracy: 0.4511 - val_loss: 1.6532 - val_accuracy: 0.4013\n",
            "Epoch 2/10\n",
            "18/18 [==============================] - 55s 3s/step - loss: 0.8824 - accuracy: 0.6379 - val_loss: 1.5108 - val_accuracy: 0.4145\n",
            "Epoch 3/10\n",
            "18/18 [==============================] - 51s 3s/step - loss: 0.5618 - accuracy: 0.7874 - val_loss: 1.7707 - val_accuracy: 0.4145\n",
            "Epoch 4/10\n",
            "18/18 [==============================] - 54s 3s/step - loss: 0.2607 - accuracy: 0.9109 - val_loss: 3.3309 - val_accuracy: 0.4737\n",
            "Epoch 5/10\n",
            "18/18 [==============================] - 55s 3s/step - loss: 0.1113 - accuracy: 0.9540 - val_loss: 4.6920 - val_accuracy: 0.4474\n",
            "Epoch 6/10\n",
            "18/18 [==============================] - 56s 3s/step - loss: 0.1387 - accuracy: 0.9540 - val_loss: 4.1062 - val_accuracy: 0.4671\n",
            "Epoch 7/10\n",
            "18/18 [==============================] - 54s 3s/step - loss: 0.0688 - accuracy: 0.9770 - val_loss: 4.1023 - val_accuracy: 0.4671\n",
            "Epoch 8/10\n",
            "18/18 [==============================] - 62s 3s/step - loss: 0.0547 - accuracy: 0.9741 - val_loss: 5.2290 - val_accuracy: 0.4605\n",
            "Epoch 9/10\n",
            "18/18 [==============================] - 53s 3s/step - loss: 0.0429 - accuracy: 0.9799 - val_loss: 5.9302 - val_accuracy: 0.4737\n",
            "Epoch 10/10\n",
            "18/18 [==============================] - 60s 3s/step - loss: 0.0420 - accuracy: 0.9799 - val_loss: 6.3597 - val_accuracy: 0.4539\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "  **4.1.   ResNet Model**\n",
        "\n"
      ],
      "metadata": {
        "id": "l0jhK-GG9StX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "\n",
        "# Mapping class data from Excel\n",
        "class_data = pd.read_excel('/content/ImageProcessingdataset.xlsx')  # Your Excel file\n",
        "class_mapping = {'S': 0, 'A': 1, 'B': 2, 'C': 3}\n",
        "class_data['Level'] = class_data['Level'].map(class_mapping)\n",
        "class_dict = dict(zip(class_data['Image ID'], class_data['Level']))\n",
        "\n",
        "def get_label(file_path):\n",
        "    if isinstance(file_path, tf.Tensor):\n",
        "        file_path = file_path.numpy().decode('utf-8')\n",
        "    image_id = os.path.basename(file_path).split('.')[0]\n",
        "    try:\n",
        "        label = class_dict[image_id]\n",
        "    except KeyError:\n",
        "        print(f\"Filename not found in class_dict: {image_id}\")\n",
        "        label = -1\n",
        "    return tf.cast(label, tf.int32)\n",
        "\n",
        "def process_path(file_path):\n",
        "    file_path = file_path.numpy().decode('utf-8')\n",
        "    img = tf.io.read_file(file_path)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)  # Update to 3 channels for ResNet50\n",
        "    img = tf.image.resize(img, [224, 224])\n",
        "    img = tf.keras.applications.resnet50.preprocess_input(img)  # ResNet specific preprocessing\n",
        "    label = tf.py_function(func=get_label, inp=[file_path], Tout=tf.int32)\n",
        "    return img, label\n",
        "\n",
        "def set_shapes(img, label):\n",
        "    img.set_shape([224, 224, 3])  # Update to 3 channels\n",
        "    label.set_shape([])\n",
        "    return img, label\n",
        "\n",
        "def create_dataset(file_paths):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(file_paths)\n",
        "    dataset = dataset.map(lambda x: tf.py_function(func=process_path, inp=[x], Tout=[tf.float32, tf.int32]))\n",
        "    dataset = dataset.map(set_shapes)\n",
        "    dataset = dataset.filter(lambda img, label: label >= 0)\n",
        "    return dataset.batch(20).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Load images and their paths\n",
        "train_dir = '/content/Training_Processed'\n",
        "test_dir = '/content/Testing_Processed'\n",
        "train_files = [os.path.join(train_dir, fname) for fname in os.listdir(train_dir) if fname.endswith(('.jpg', '.jpeg'))]\n",
        "test_files = [os.path.join(test_dir, fname) for fname in os.listdir(test_dir) if fname.endswith(('.jpg', '.jpeg'))]\n",
        "\n",
        "# Create datasets for training and testing\n",
        "train_dataset = create_dataset(train_files)\n",
        "test_dataset = create_dataset(test_files)\n",
        "\n",
        "# ResNet50 Model Definition\n",
        "def create_resnet_model():\n",
        "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "    base_model.trainable = False  # Freeze the convolutional base\n",
        "    x = GlobalAveragePooling2D()(base_model.output)\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    predictions = Dense(4, activation='softmax')(x)\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Create and train the ResNet model\n",
        "model = create_resnet_model()\n",
        "history = model.fit(train_dataset, epochs=10, validation_data=test_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DW3V2mhmuOIh",
        "outputId": "8737de51-ea2e-4680-e31a-a094f94e3319"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "18/18 [==============================] - 114s 6s/step - loss: 1.9955 - accuracy: 0.3534 - val_loss: 1.6965 - val_accuracy: 0.3618\n",
            "Epoch 2/10\n",
            "18/18 [==============================] - 100s 6s/step - loss: 1.2405 - accuracy: 0.5661 - val_loss: 1.8989 - val_accuracy: 0.3684\n",
            "Epoch 3/10\n",
            "18/18 [==============================] - 108s 6s/step - loss: 0.9191 - accuracy: 0.5833 - val_loss: 1.7777 - val_accuracy: 0.3750\n",
            "Epoch 4/10\n",
            "18/18 [==============================] - 110s 6s/step - loss: 0.8241 - accuracy: 0.6609 - val_loss: 1.9034 - val_accuracy: 0.4211\n",
            "Epoch 5/10\n",
            "18/18 [==============================] - 109s 6s/step - loss: 0.7685 - accuracy: 0.6580 - val_loss: 1.9384 - val_accuracy: 0.3947\n",
            "Epoch 6/10\n",
            "18/18 [==============================] - 111s 6s/step - loss: 0.6920 - accuracy: 0.7126 - val_loss: 1.8426 - val_accuracy: 0.4276\n",
            "Epoch 7/10\n",
            "18/18 [==============================] - 109s 6s/step - loss: 0.6637 - accuracy: 0.7385 - val_loss: 1.8543 - val_accuracy: 0.4539\n",
            "Epoch 8/10\n",
            "18/18 [==============================] - 109s 6s/step - loss: 0.6200 - accuracy: 0.7270 - val_loss: 1.8978 - val_accuracy: 0.3947\n",
            "Epoch 9/10\n",
            "18/18 [==============================] - 111s 6s/step - loss: 0.5482 - accuracy: 0.7960 - val_loss: 2.0539 - val_accuracy: 0.3816\n",
            "Epoch 10/10\n",
            "18/18 [==============================] - 107s 6s/step - loss: 0.5006 - accuracy: 0.8017 - val_loss: 2.0404 - val_accuracy: 0.4408\n"
          ]
        }
      ]
    }
  ]
}